# models.py
# Author: Jacob Schreiber <jmschreiber91@gmail.com>

import time
import numpy
import torch

from tqdm import trange

from bpnetlite.losses import MNLLLoss
from bpnetlite.losses import log1pMSELoss

from bpnetlite.performance import pearson_corr
from bpnetlite.performance import calculate_performance_measures

from bpnetlite.logging import Logger

from tangermeme.predict import predict


class DragoNNFruit(torch.nn.Module):
	"""An entire DragoNNFruit model with all components.

	DragoNNFruit is a deep learning method for analyzing single cell ATAC-seq
	data. This can be from scATAC-seq data alone, the scATAC-seq component of
	a multiome experiment. At a high level, it takes in nucleotide sequence,
	a representation of cell state, and makes basepair-level predictions of
	chromatin accessibility.

	Briefly, a DragoNNFruit model is made up of three components. The first is
	a bias model, similar to those trained for ChromBPNet models, that captures
	the sequence basis of the TN5 cutting enzyme itself which are not driven by
	real biology. The second is a convolutional neural network similar to a
	ChromBPNet model, where nucleotide sequence is run through successive
	layers of convolutions. However, the weights of these convolutions are not
	static after training, like for a ChromBPNet model. Rather, the third
	component is a dense neural network that takes in a user-defined cell state
	and outputs the parameters of these convolutions (either the full weight
	matrix or just the bias terms for each filter). This conditions the
	processing of sequence on cell state.

	This object is a wrapper for those three components with an attached
	fitting function. The components can be accessed, respectively, as
	`self.bias`, `self.accessibility`, and `self.accessibility.controller`.

	In the same way that a ChromBPNet model is two BPNet models holding hands
	(at a high level), DragoNNFruit is a BPNet model holding hands with a
	`DynamicBPNet` model, where the "dynamic" part comes because its parameters
	are being generated by the controller. 


	Parameters
	----------
	bias: bpnetlite.bpnet.BPNet
		This model takes in sequence and outputs the shape one would expect in 
		ATAC-seq data due to Tn5 bias alone. This is usually a BPNet model
		from the bpnet-lite repo that has been trained on GC-matched non-peak
		regions.

	accessibility: dragonnfruit.models.DynamicBPNet
		This model takes in sequence and outputs the accessibility one would 
		expect due to the components of the sequence, but also takes in a cell 
		representation which modifies the parameters of the model, hence, 
		"dynamic." This model is usually a DynamicBPNet model, defined below.

	name: str
		The name to prepend when saving the file.

	verbose: bool, optional
		Whether to print logs to the screen during training. 
	"""

	def __init__(self, bias, accessibility, name, verbose=True):
		super(DragoNNFruit, self).__init__()

		for parameter in bias.parameters():
			parameter.requires_grad = False

		self.bias = bias
		self.accessibility = accessibility
		self.name = name
		self.logger = Logger(["Iteration", "Training Time",
			"Validation Time", "Training MNLL", "Validation MNLL",
			"Validation Profile Correlation", "Validation Count Correlation", 
			"Saved?"], verbose=verbose)


	def forward(self, X, cell_states, read_depths):
		"""A forward pass through the entire set of three models.

		This function will take in a batch of sequences, cell states, and read
		depths, and make predictions. Each tensor must have the same first
		dimension and the i-th element in each tensor should be matched. For
		example, the first prediction that is returned will be from the
		first sequence in X, the first cell state, and the first read depth.


		Parameters
		----------
		X: torch.tensor, shape=(-1, 4, 2114)
			A one-hot encoded sequence tensor.

		cell_states: torch.tensor, shape=(-1, n_nodes)
			A tensor representing the state of each cell that is passed into
			the model, e.g. through PCA or LSI.

		read_depths: torch.tensor, shape=(-1, 1)
			A tensor containing the read depth of each cell or aggregated
			across similar cells.


		Returns
		-------
		y_profile: torch.tensor, shape=(-1, 1000)
			The predicted logit profile for each example. Note that this is not
			a normalized value.
		"""

		return read_depths + self.bias(X)[0][:, 0] + self.accessibility(X,
			cell_states)


	@torch.no_grad()
	def predict(self, X, cell_states, read_depths, batch_size=16, 
		reduction=None, verbose=False):
		"""A method for making batched predictions.

		This method will take in a large number of cell states and provide
		predictions in a batched manner without storing the gradients. Useful
		for inference step.

		We use a custom function here instead of relying on tangermeme because
		we need the option to aggregate the results as they are being generated
		to make count predictions.


		Parameters
		----------
		X: torch.tensor, shape=(-1, 4, 2114)
			A one-hot encoded sequence tensor.

		cell_states: torch.tensor, shape=(-1, n_inputs)
			A tensor representing the state of each cell that is passed into
			the model, e.g. through PCA or LSI.

		read_depths: torch.tensor, shape=(-1, 1)
			A tensor containing the read depth of each cell or aggregated
			across similar cells.

		batch_size: int, optional
			The number of elements to use in each batch. Default is 64.

		reduction: None, 'logsumexp', or 'sum', optional
			Whether to reduce the predictions along the final axis. Useful to
			reduce the memory overhead of making large number of predictions.
			If None, perform no reduction. Default is None.

		verbose: bool, optional
			Whether to display a progress bar across batches. Default is False.


		Returns
		-------
		y_hat: torch.tensor, shape=(-1, 1000) or (-1, 1)
			A tensor containing the predicted profiles.
		"""		

		y_hat = []
		for start in trange(0, len(X), batch_size, disable=not verbose):
			X_batch = X[start:start+batch_size]
			cs_batch = cell_states[start:start+batch_size]
			rd_batch = read_depths[start:start+batch_size]

			y_hat_ = self(X_batch, cs_batch, rd_batch)
			if reduction == 'sum':
				y_hat_ = torch.sum(y_hat_, dim=-1)
			elif reduction == 'logsumexp':
				y_hat_ = torch.logsumexp(y_hat_, dim=-1)

			y_hat.append(y_hat_)

		y_hat = torch.cat(y_hat)
		return y_hat


	@torch.no_grad()
	def predict_cross(self, X, cell_states, read_depths, batch_size=64,
		reduction=None, verbose=False):
		"""A method for making batched predictions on a locus/cell cross.

		This method makes predictions for a cross between loci and cell states.
		Use this method and not `predict` when you want to make predictions
		for all loci for all cell states. Because the cross is constructed
		in batches the amount of memory required is limited and the size
		of the loci and cell states do not need to match in the first
		dimension.


		Parameters
		----------
		X: torch.tensor, shape=(n_loci, 4, 2114)
			A one-hot encoded sequence tensor.

		cell_states: torch.tensor, shape=(n_states, n_inputs)
			A tensor representing the state of each cell that is passed into
			the model, e.g. through PCA or LSI.

		read_depths: torch.tensor, shape=(n_states, 1)
			A tensor containing the read depth of each cell or aggregated
			across similar cells.

		batch_size: int, optional
			The number of elements to use in each batch. Default is 64.

		reduction: None, 'logsumexp', or 'sum', optional
			Whether to reduce the predictions along the final axis. Useful to
			reduce the memory overhead of making large number of predictions.
			If None, perform no reduction. Default is None.

		verbose: bool, optional
			Whether to display a progress bar across states. Default is False.


		Returns
		-------
		y_hat: torch.tensor, shape=(n_loci, n_states, 1000)
			A tensor containing the predicted profiles.
		"""		

		n_states = cell_states.shape[0]
		y_hat = []

		for i in trange(n_states, disable=not verbose):
			_y_hat = self.predict(X, cell_states[i:i+1].expand(X.shape[0], -1), 
				read_depths=read_depths[i:i+1].expand(X.shape[0], -1),
				batch_size=batch_size, reduction=reduction)
			y_hat.append(_y_hat)

		return torch.stack(y_hat)


	def _train_step(self, X, cell_states, read_depths, y, optimizer, dtype):
		"""An internal function for a single training step."""

		optimizer.zero_grad()

		with torch.autocast(device_type='cuda', dtype=dtype):
			y_hat = self(X, cell_states, read_depths)

		y_hat_ = torch.nn.functional.log_softmax(y_hat.flatten(), dim=-1)
		loss = MNLLLoss(y_hat_, y.flatten())

		loss_ = loss.item()
		loss = loss.backward()

		torch.nn.utils.clip_grad_norm_(self.parameters(), 1)
		optimizer.step()
		return loss_

	def fit(self, training_data, validation_data, optimizer, scheduler=None,
		n_valid=5000, max_iter=1000000, batch_size=64, validation_iter=100, 
		dtype=torch.bfloat16):
		"""Fit an entire DragoNNFruit model to the data.

		This method handles the fitting of a DragoNNFruit model to data and the
		periodic evaluation of it on validation data. Although the bias model
		will be frozen at the beginning of training -- similar to when a
		ChromBPNet model is being trained -- the accessibility model and the
		controller model will both have weights updated each iteration.

		Batches of data are generated by the `training_data` generator and
		consist of nucleotide sequences, cell states, and read depths for those
		cells. DragoNNFruit then trains on this batch of data in a fairly
		standard manner except that the softmax at the end is taken across all
		examples in the batch. This choice means that the logits predicted by
		the model have a magnitude that is relatively correct (as in, a correct
		ranking, not "almost" correct) in both sequence space and in cell
		space. 

		Every `validation_iter` batches, the model is evaluated on a fixed set
		of validation data. This ensures a consistent evaluation during
		training because the examples being considered remain the same. 
		`n_valid` examples are drawn from `validation_data`, which
		should be indexable. 

		Training will proceed for `max_n_batches` number of batches. During
		training, the best model according to validation set performance will
		be saved. At the end of training, the final parameters of the model will
		be saved to a separate file.


		Parameters
		----------
		training_data: torch.utils.data.DataLoader
			A generator of training data that yields batches of data, with each
			cell returning a tuple of sequences, true signal, cell states, and 
			read depths. The true signal must be per-nucleotide signal of 
			whatever form is being trained on, e.g. counts summed as a dynamic
			pseudobulk over the corresponding cell.

		validation_data: dragonnfruit.io.LocusGenerator
			A generator of loci to validate on. This must generate tuples
			that include sequences, true signal, cell state, and read depths.

		optimizer: torch.optim.Optimizer
			An optimizer to control how parameter weights change during
			training.

		scheduler: torch.optim.lr_scheduler, optional
			An optional learning rate scheduler which changes the learning rate
			across batches. If None, do not use a scheduler. Default is None.

		n_valid: int, optional
			The number of examples to use to for validation. This will select
			the first `n` examples from `validation_data`. In general, it is
			good to make this as big as you are willing to do but to also make
			`validation_iter` larger alongside it so you do not spend too much
			time doing validation. Default is 5000.

		max_iter: int, optional
			The maximum number of batches to train for. When doing genome-wide
			training there is not a notion of an "epoch" that is meaningful and
			so we measure everything in terms of batches. Default is 1000000.

		batch_size: int, optional
			The number of examples in each batch. This should be as large as
			possible to stabilize the variance. Default is 64.

		validation_iter: int, optional
			The number of batches to train on before evaluating on all of the
			validation set examples. In general, this should be set such that
			no more than 10% of total time is spent doing validation, though
			closer to 1% may be preferable. Default is 100.

		dtype: torch.dtype, optional
			The dtype to use during training. If set to `torch.float32` will
			train at full precision. Setting to `torch.float16` is generally
			not stable and so it is advised to use `torch.bfloat16` instead.
			Default is `torch.bfloat16`.
		"""

		X_valid, y_valid, c_valid, r_valid = zip(*[validation_data[i]
			for i in range(n_valid)])
		X_valid = torch.stack(X_valid).cuda().type(torch.float32)
		y_valid = torch.stack(y_valid).cuda().type(torch.float32)
		c_valid = torch.stack(c_valid).cuda()
		r_valid = torch.stack(r_valid).cuda()

		start, best_corr = time.time(), 0
		self.logger.start()

		for i, (X, y, cell_states, read_depths) in enumerate(training_data):
			if i == max_iter:
				break

			X = X.cuda().type(torch.float32)
			y = y.cuda()
			cell_states = cell_states.cuda()
			read_depths = read_depths.cuda()

			train_loss = self._train_step(X, cell_states, read_depths, y,
				optimizer, dtype)

			if i % validation_iter == 0:
				scheduler.step()

				train_time = time.time() - start
				tic = time.time()

				# Make predictions on the validation set
				y_hat = predict(self, X_valid, args=(c_valid, r_valid), 
					batch_size=batch_size).cuda()
				
				# Calculate MNLL loss
				y_hat_ = torch.nn.functional.log_softmax(y_hat.flatten(), 
					dim=-1)
				valid_loss = MNLLLoss(y_hat_, y_valid.flatten()).item()

				# Calculate count correlation
				y_hat_ = torch.logsumexp(y_hat, dim=-1)
				valid_count_corr = pearson_corr(y_hat_, torch.log2(y_valid.sum(dim=-1) + 1))
				valid_count_corr = valid_count_corr.mean().item()

				# Calculate profile correlation
				y_hat = torch.nn.functional.log_softmax(y_hat.flatten(), 
					dim=-1).reshape(*y_hat.shape)
				y_hat = torch.exp(y_hat)
				valid_profile_corr = pearson_corr(y_hat, 
					y_valid).mean().item()

				valid_time = time.time() - tic

				# Store results in the logging object
				self.logger.add([i, train_time, valid_time, 
					train_loss, valid_loss, valid_profile_corr, 
					valid_count_corr, valid_profile_corr > best_corr])

				self.logger.save("{}.log".format(self.name))

				# Save the model if it's the best thus-far
				if valid_profile_corr > best_corr:
					best_corr = valid_profile_corr
					torch.save(self, "{}.best.torch".format(self.name))

				start = time.time()

		torch.save(self, "{}.torch".format(self.name))


class DynamicBPNet(torch.nn.Module):
	"""A BPNet model whose weights are modified by an external factor.

	This model has the same architecture as the original BPNet model but the
	parameters of the residual convolution layers are controlled by some
	external factor. Specifically, in this model, the bias terms for the
	residual convolution layers are predicted from the provided cell states.
	The first and last convolution layers -- which are by far the largest --
	are not modified at all. 

	An important detail is that this model does not consider read depth of
	cells. Read depth is added to the predictions from this model when it is
	part of the DragoNNFruit wrapper. This model is meant to represent
	predictions free from read depth bias and from Tn5 bias.
	

	Parameters
	----------
	controller: torch.nn.Module
		This model takes in the cell representation and outputs a 
		representation that will be fed into the dynamic accessibility model.
		This model is usually a CellStateController model, as defined below.

	n_filters: int, optional
		The number of filters to use in each convolution layer. Default is 128.

	n_layers: int, optional
		The number of residual dilated convolutions sandwiched between the
		first and the last layer. Does not include the size of the first
		and the last layer. Default is 8.

	trimming: int or None, optional
		The amount of trimming to apply to input sequences to go from the size
		of the input to the size of the output predictions. If none, will
		automatically trim to 2 ** n_layers + 37. Default is None.

	conv_bias: bool, optional
		Whether the convolutions should have learned bias terms in addition
		to those learned from the cell state repressentation. Mostly only
		useful when transferring weights from a pre-trained model.
	"""

	def __init__(self, controller, n_filters=128, n_layers=8, trimming=None, 
		conv_bias=False):
		super(DynamicBPNet, self).__init__()

		self.trimming = trimming or 2 ** n_layers + 37
		self.n_filters = n_filters
		self.n_layers = n_layers


		self.iconv = torch.nn.Conv1d(4, n_filters, kernel_size=21, padding=10)
		self.irelu = torch.nn.ReLU()
		self.fconv = torch.nn.Conv1d(n_filters, 1, kernel_size=75, padding=37,
			bias=conv_bias)

		self.biases = torch.nn.ModuleList([
			torch.nn.Linear(controller.n_outputs, n_filters) for i in range(
				n_layers)
		])

		self.convs = torch.nn.ModuleList([
			torch.nn.Conv1d(n_filters, n_filters, kernel_size=3, stride=1, 
				dilation=2**i, padding=2**i, bias=conv_bias) for i in range(1, 
					n_layers+1)
		])

		self.relus = torch.nn.ModuleList([
			torch.nn.ReLU() for i in range(n_layers)
		])

		self.controller = controller


	def forward(self, X, cell_states):
		"""A forward pass through the network.

		This function is usually accessed through calling the model, e.g.
		doing `model(x)`. The method defines how inputs are transformed into
		the outputs through interactions with each of the layers.


		Parameters
		----------
		X: torch.tensor, shape=(-1, 4, 2114)
			A one-hot encoded sequence tensor.

		cell_states: torch.tensor, shape=(-1, n_nodes)
			A tensor representing the state of each cell that is passed into
			the model, e.g. through PCA or LSI.


		Returns
		-------
		y_profile: torch.tensor, shape=(-1, 1000)
			The predicted logit profile for each example. Note that this is not
			a normalized value.
		"""

		start, end = self.trimming, X.shape[2] - self.trimming
		
		cell_states = self.controller(cell_states)
		X = self.irelu(self.iconv(X))

		for i in range(self.n_layers):
			X_conv = self.convs[i](X)
			X_bias = self.biases[i](cell_states).unsqueeze(-1)

			X = X + self.relus[i](X_conv + X_bias)

		y_profile = self.fconv(X)[:, 0, start:end]
		return y_profile


	def load_conv_weights(self, filename, freeze=False):
		"""Load convolution weights from a pretrained ChromBPNet model.

		This function will load the convolution weights from a pre-trained
		model. Specifically, it will load the convolutions from the 
		`accessibility` attribute of the model. Must have the same number
		of layers and filter sizes.


		Parameters
		----------
		filename: str
			The filename of the model to load.

		freeze: bool, optional
			Whether to freeze the layers whose weights are loaded.
		"""

		device = next(self.parameters()).device
		model = torch.load(filename, map_location='cpu').to(device)
		model = model.accessibility

		self.iconv.weight = torch.nn.Parameter(model.iconv.weight)
		self.iconv.weight.requires_grad = not freeze

		self.iconv.bias = torch.nn.Parameter(model.iconv.bias)
		self.iconv.bias.requires_grad = not freeze

		for sconv, mconv in zip(self.convs, model.rconvs):
			sconv.weight = torch.nn.Parameter(mconv.weight)
			sconv.weight.requires_grad = not freeze

			sconv.bias = torch.nn.Parameter(mconv.bias)
			sconv.bias.requires_grad = not freeze

		self.fconv.weight = torch.nn.Parameter(model.fconv.weight)
		self.fconv.weight.requires_grad = not freeze


class CellStateController(torch.nn.Module):
	"""A controller of DynamicBPNet parameters using cell state.

	This component of the DragoNNFruit model concerns taking in cell states
	and transforming them somehow. It is passed into the DynamicBPNet model
	and provides the representations that are used to control the parameters
	of the model. 


	Parameters
	----------
	n_inputs: int
		The number of dimensions in the input cell representation.

	n_nodes: int, optional
		The number of nodes in the internal neural network layers. Default
		is 256.

	n_outputs: int, optional
		The number of dimensions in the output cell representation. Default
		is 64.

	n_layers: int, optional
		The total number of internal layers to apply to the representations,
		not including the first layer that transforms the representations from
		input representations to the internal representations or the last
		layer that transforms from the internal representations to the output
		representations. Default is 0.
	"""

	def __init__(self, n_inputs, n_nodes=256, n_outputs=64, n_layers=0):
		super(CellStateController, self).__init__()

		self.n_inputs = n_inputs
		self.n_nodes = n_nodes
		self.n_outputs = n_outputs
		self.n_layers = n_layers

		self.ifc = torch.nn.Linear(n_inputs, n_nodes)
		self.irelu = torch.nn.ReLU()

		self.fcs = torch.nn.ModuleList([
			torch.nn.Linear(n_nodes, n_nodes) for i in range(n_layers)
		])
		self.relus = torch.nn.ModuleList([
			torch.nn.ReLU() for i in range(n_layers)
		])

		self.ffc = torch.nn.Linear(n_nodes, n_outputs)


	def forward(self, cell_states):
		"""A forward pass through the network.

		This function is usually accessed through calling the model, e.g.
		doing `model(x)`. The method defines how inputs are transformed into
		the outputs through interactions with each of the layers.


		Parameters
		----------
		cell_states: torch.tensor, shape=(-1, n_inputs)
			A tensor representing the state of each cell that is passed into
			the model, e.g. through PCA or LSI.


		Returns
		-------
		cell_states: torch.tensor, shape=(-1, n_outputs)
			A tensor representing the transformed state of each cell.
		"""

		cell_states = self.irelu(self.ifc(cell_states))
		for i in range(self.n_layers):
			cell_states = self.relus[i](self.fcs[i](cell_states))

		cell_states = self.ffc(cell_states)
		return cell_states
